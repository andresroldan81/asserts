= TODO
:lang:		es
:author:	Enginering Team
:email:		engineering@fluid.la
:revnumber:	v1.0
:revdate:	{date}

== Funcionalidades

. http://dl.acm.org/citation.cfm?id=2896929 Automatic web security unit
  testing: XSS vulnerability detection

== Errores

. Solucionar los problemas de compilacion de YAML en CircleCI no ocurren, pero
  en los ambientes normales si

. Resolver los warnings de compilación de YAML (quitar YAML?)
  https://www.atlassian.com/git/tutorials/git-hooks/

. La generacion de txt de la documentación sale con errores de visualicion en
  caracteres extraños al parecer son problemas de codificación.

== Dependencias

. El venv solo funciona bien en ubuntu, a andrew le toco hacer un hack para que
  funcione en version 3.5 y en sid, posiblemente sea mejor trabajar asi:
  instalar python en el sistema, el que sea, y luego desde pip instalar el venv
  para poder forzar el uso de una version particular con ==

. Las dependencias de desarrollo deberian ser otras a las dependencias de
  ejecucion, por tal motivo deben existir dos archivos de requirements, uno
  para desarrollo y otro para ejecucion: requirements-dev.txt?

. Ya esta la dependencia en ubuntu6 de libffi??

. requirements.txt a docker-py??

. Eliminar configobj y utilizar el parser standard configparser, eliminar
  archivos de configuracion innecesarias, archivos a distribuir innecesarios,
  etc.  Inspirarse en el mismo manejo que hace tox de los ini o setuptools

. Separar la configuración que se encuentra en el codigo seleccionando una de
las siguientes bibliotecas:
https://bitbucket.org/ruamel/yaml
http://www.voidspace.org.uk/python/configobj.html
https://docs.python.org/3/library/configparser.html
https://pypi.python.org/pypi/python-decouple
https://github.com/osantana/prettyconf
https://github.com/ssato/python-anyconfig
https://bitbucket.org/dhagrow/profig/

== Versionamiento

. Utilizar el archivo de configuracon config del raiz del repo git para
  adicionar comandos comunes de git como git root.
git config --global alias.root 'rev-parse --show-toplevel'

. Definir en la nueva documentación el nuevo workflow de trabajo simplificado
. Sera que toco hacer esto por la nueva forma de crear el branch:
  $ git branch --set-upstream-to=origin/master ralvarez

. Donde estoy en GIT
  $ git --no-pager log --graph --oneline --decorate --date=relative --all -10

. Contar algo antes de hacer el prune (nueva tarea?):
  $ git count-objects -v

. Mantenimiento al repositorio borrando ya los commits no asociados a un branch
  $ git gc --prune=now

. Si algunas ramas que estan remote y fueron sincronizadas localmente fueron
  eliminadas de remote, pueden purgarse localmente con:
  $ git remote prune origin

. Este comando parece que hace la limpieza local de ramas que ya no existen
  en remote???
  $ git fetch --all --prune

. Comandos a hacer localmente para eliminar la rama develop:
  $ git branch --set-upstream-to=origin/master ralvarez
  $ git branch -d develop
  $ git remote prune origin
  $ git gc --prune=now

== Estilo

. Analizar esta opción de precommit:
  https://github.com/jish/pre-commit

. Entre el import sorter de precommit y flake8 se contradicen.

. Incluir extensiones que permiten generar errores en el caso de que los
  parametros de configuración no tengan documentación.
https://docs.pylint.org/en/1.6.0/extensions.html

. Incluir las extensiones de linting que permiten verificar la complejidad
  ciclomatica o complejidad de McCabe de ciertos metodos:
https://docs.pylint.org/en/1.6.0/extensions.html

. Incluir isort en las bibliotecas de desarrollo
  https://pypi.python.org/pypi/isort
  https://github.com/ionelmc/cookiecutter-pylibrary/blob/master/%7B%7Bcookiecutter.repo_name%7D%7D/setup.cfg

. Reducir los errores de flake8

. Hay errores de flake8 que salen en el linting a traves de lint y esos mismos
  errores no salen en el linting que se dispara desde el pre-commit.

. Analizar la configuracion de pylint para ver si se puede personalizar en el
  Failed correspondiente, por determinado puntaje que logre el codigo

. Analizar cambio en la arquitectura de linters: frosted vs pyflakes
  https://github.com/klen/pylama

== Documentación

. Crear seccion de documentación explicando como registrar la clave SSH
  en bitbucket para hacer commit sin auth y para que desde circle todo
  funcione.
https://confluence.atlassian.com/bitbucket/set-up-ssh-for-git-728138079.html

. Añadir que en el /etc/hosts se agregue una linea que contenga el nombre del
  contenedor de docker que se usara para todas las pruebas.

. Falta explicar en la documentación cuando hay que hacer push.

. Despues de la sección de registro y cuando se pasa a la sección de descarga,
  no se habla de como se hace el login o como son los pasos de git login
  preliminares.

. Clarificar que el requerimiento es que funcione pyinvoke y pyenv, punto,
  independiente del interprete de python. O clarificar en la documentacion el
  tema de los ambientes virtuales, las versiones, etc

. Sera mas facil clarificar que debe haber un commit por comentario y no muchos
  diff con muchos comentarios.

. Revisar la documentación generada por Sphinx a Alabaster

. Guia sobre como debe documentarse un commit
  https://wiki.openstack.org/wiki/GitCommitMessages

. Adicionar guia de como hacer commits por cada caracteristica particular y
  por ende como fragmentar varios cambios en varios commit:
  http://nuclearsquid.com/writings/git-add/
  http://alblue.bandlem.com/2011/10/git-tip-of-week-interactive-adding.html

== Pruebas

. Utilizar markers para distinguir pruebas en diferentes ambitos:
  * archivos, contenedores, integración, listas,
  http://pytest.org/2.2.4/example/markers.html

. Pasar los parametros de pytest de tox.ini a:
  http://doc.pytest.org/en/latest/customize.html

. Pruebas randomizadas funcionan?

. Parametrizar pytest mediante seccion en tox.ini y no solo mediante parametros
  de comandos

. Eliminar los printf de los suite de pruebas y analizar la opcion de
  invocar con menos -s pytest y hacer log debug

. Analizar el uso de parametrized test para no tener 2 funciones para abierto
  y cerrado, sino solo una prueba que tenga parametrizadas las dos opciones

. Permitir la instalación de este modulo para la ejecución de comandos
  individuales https://github.com/dstanek/tox-run-command

. Debido al uso de docker y de comunicación entre servidores a veces no
  funciona las pruebas de unidad por problemas de comunicación con el host o
  timeout.

. Incoportar en la suite de integracion las pruebas que hacen funcionar docker
  y ansible.

. Pre.commit hooks in server side
  https://git-scm.com/book/en/v2/Customizing-Git-An-Example-Git-Enforced-Policy

. Volver a revisar tox o doit como herramientas de integracion
https://testrun.org/tox/latest/

. Tox testing para multiples versiones de python:
  https://discuss.circleci.com/t/testing-in-different-environments/450/2
  https://discuss.circleci.com/t/testing-with-multiple-python-versions/4420

. Pruebas unitarias de los mensajes de error en los logs?
  https://pypi.python.org/pypi/pytest-capturelog

. Hacer refactoring de las suites de pruebas para que sean menos
  repetitivas:
  http://doc.pytest.org/en/latest/parametrize.html

. Testing de multiples versiones de python en circleci
  https://ben.fogbutter.com/2016/02/20/testing-multiple-python-versions-on-circleci.html

. Crear archivo de configuracion de coverage que permita ademas de centralizar
  los parametros de configuracion de la aplicacion, establecer una meta
  de coverage antes de fallar:
  https://coverage.readthedocs.io/en/latest/config.html

== Construccion

. Muchos de los scripts tal vez no requieran crear un tool o un builder para ser
  reutilizados, simplemente requieren ser invocados una vez cuando se invoca un
  alias:
http://scons.org/doc/2.0.1/HTML/scons-user/c3762.html

. Mejorar los script de scons con:
  https://chromium.googlesource.com/native_client/src/native_client/+/master/SConstruct

. Analizar porque con scons se tarda dos ejecuciones en no ejecutar mas codigo
  sera que la ejecución cambia el fuente al ejecutar y generar los pyc y
  los directorios de cache? sera que lo soluciona la opcion de Variant de Scons.

. Migrar de invoke y shell scripts de docker y de asciidoc a scons. La
  instalación de scons funciono muy bien pero despues de hacer actualización de
  pip y setuptools asi: Mejorar en la documentación si se migra.
  $ pip install -U pip setuptools --egg scons

. Al migrar a scons se logra cache de los archivos origen antes de make
  evitando el clean constante y dejando la tarea de cache al software de
  construcción.  Ademas se mantiene python y la infraestructura multiplatform.
  Adicionalmente unifica los scripts de bash que se estan volviendo
  constantes en: documentación, docker, ansible, pruebas, etc.

. En la documentación explicar que se puede colocar esto para que no se haga un
  build con un commit que no aplica:
https://circleci.com/docs/skip-a-build/

. oirganizar tags y nombres de container de fluidasserts en docker pues estan
  un desorden sin agrupación de producto:
  https://hub.docker.com/r/fluidsignal/containers/

. Verificar si estas claves individuales las puede ver cualquier persona o si
  cada persona debe establecer sus claves en el propios build:
  https://circleci.com/bb/fluidsignal/fluid-asserts/edit#env-vars

. Porque iniciar el container es tan lento si ya tenemos la imagen con los
  paquetes listos.

. Utilizar timeouts en la duración de los test para generar fallos en la
  compilación si esta se demora mucho, ademas poder detener el servicio para
  otra compilación y no gastar mucho de los servicios gratuitos: timeout: 1200

. Acelerar la ejecución de las pruebas:
.. Considerando ssh pipelining
.. Deshabibilitando los facters
.. Habilitando el profile de ansible
.. Reorganizando en roles o con tags para que no se repitan tareas.
... instalar - provision
... config??
... hack
... harden
... desintarlar

. Adicionar verificación que no permite que el software se ejecute como *root*.

. Adicionar cloc en el proceso de integracion continua y build

. o en su efecto utilizar TestInfra http://testinfra.readthedocs.io/en/latest/

. Crear una imagen docker de FLUIDAsserts

. O con docker compose:
  http://www.heavybit.com/library/blog/opinionated-tour-of-testing-tools/

. Tasks que gestionen el deployment

. Forzar con Collections en PyInvoke el LANG:
  $ export LANG=C

. La generación de artifacts en CI no invoca la generación de la documentación
  que se genera con asciidoc

. El buildlog de CI no invoca aun el task de size que hace cloc, posiblemente
  necesita la dependencia

== Empaquetamiento

. Es Flask una dependencia de ejecución (hoy en setup.py) o es una dependencia
  de pruebas solo para los mock y por ende debe ir en la definición de
  ambientes.

. Entry point en setup.py que permita la ejecución de un exploit al ejecutar el
  modulo?  python -m fluidasserts exploit.py???

. Mover el fuente de fluidasserts a src, revisar en detalle este documento:
https://blog.ionelmc.ro/2014/05/25/python-packaging/

. Determinar las implicaciones de añadir el parametro faltante en setup.py
  platforms='ANY'

== Productos

. Historico de cobertura con: https://coveralls.io/

. Historico de calidad de codigo: https://codeclimate.com/

. https://circleci.com/docs/code-coverage/

. Integracion continua en Windows: https://www.appveyor.com/

== Estandares

. Analizar el compliance con TAP como protocolo de salida estandar:
http://testanything.org/

== Virtualización

. Convertir los scripts de construcción de la imagen a scons y posiblemente
  simplificarlos a un solo archivo inspirado en el Makefile sobre la imagen
  de debian en la que esta basada la construcción del sistema.
https://hub.docker.com/r/krlmlr/debian-ssh/

. Verificar si ansible en ves de ser una dependencia del SO, puede quedar
  como una dependencia de requierements-test.txt (tox.ini y que se instale solo
  en dicho escenario en el ambiente virtual.

. Por algun problema de docker el repositorio de fluidasserts quedo publico:
https://success.docker.com/Cloud/Solve/Pull_error_%E2%80%9DThe_Repository_is_Locked,_access_denied%22
https://forums.docker.com/t/pull-error-the-repository-is-locked-access-denied/2178/14
https://github.com/docker/kitematic/issues/1464

. Poner un trabajo para que las imagenes se construyan solas en docker-hub.
https://docs.docker.com/engine/tutorials/dockerrepos/#/automated-builds

. El modulo apt de ansible siempre va a internet a jalar archivos, la unica
  opcion no probada es esta de apt-cacher-ng-offline, la no offline requiere
  correr un servicio apache localmente o tener otro docker.
https://lostechies.com/ryanrauh/2015/01/28/how-to-easily-apt-get-update-offline/
http://askubuntu.com/questions/306971/install-package-along-with-all-the-dependencies-offline
https://help.ubuntu.com/community/AptGet/Offline/Repository/

. Utilizar el modulo async de ansible para ejecución paralela de tasks.

. Los fixtures solo ejecutan los tags vulnerable y no vulnetable, por ende no
  corren los playbooks de debian (base) ni los tanks sin tag.  Estas dos son
  dependencias criticas para la ejecución del playbook.

. En vez de utilizar los scripts de inicio de docker, puede que docker compose
  facilite el inicio y fin de los diferentes servidores de docker asi como
  las especificación de las interfaces de red correspondientes.
http://stackoverflow.com/questions/31787426/can-circle-ci-use-docker-compose-to-build-the-environment
https://www.theodo.fr/blog/2016/05/straight-to-production-with-docker-ansible-and-circleci/

. Este wrapper permite manejar ambientes virtuales de python ya sea pyvenv o
  virtualenv, parece en inicio mas maduro que los otros
  http://pyvenvwrapper.readthedocs.io/en/latest/index.html tiene la ventaja de
  poder ser instalado via pip y por ende hacerlo mas independiente del
  empaquetamiento propio del sistema local

include::include/footer.adoc[]
